{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "average-campaign",
   "metadata": {},
   "source": [
    "# OpenAI Gym: Acrobot-v1\n",
    "\n",
    "This notebook shows how grammar-guided genetic programming (G3P) can be used to solve the Acrobot-v1 problem from OpenAI Gym. This is achieved by searching for a small program that defines an agent, who uses an algebraic expression of the observed variables to decide which action to take in each moment.\n",
    "\n",
    "Caution: This notebook was run with gym v0.20.0 (pip install gym==0.20.0) and pyglet v1.5.27 (pip install pyglet==1.5.27). Gym deprecated \"Pendulum-v0\" from v0.20.0 to v.0.21.0. Gym changed its API from v0.25.2 to v0.26.0. Pyglet changed its API from 1.5.27 to 2.0.0.\n",
    "\n",
    "## References\n",
    "\n",
    "- Wikipedia\n",
    "\n",
    "  - [Closed-form expression](https://en.wikipedia.org/wiki/Closed-form_expression)\n",
    "\n",
    "- OpenAI Gym website\n",
    "\n",
    "  - [Classic problems from control theory](https://gym.openai.com/envs/#classic_control): an overview of environments\n",
    "  - [Acrobot-v1](https://gym.openai.com/envs/Acrobot-v1): the environment solved here\n",
    "\n",
    "- Book by Richard Sutton, original author of the Acrobot problem\n",
    "\n",
    "  - [The Acrobot](http://incompleteideas.net/book/11/node4.html)\n",
    "- GitHub\n",
    "  - [Leaderboard](https://github.com/openai/gym/wiki/Leaderboard#acrobot-v1): community wiki to track user-provided solutions\n",
    "  - [Example solution](https://github.com/ZhiqingXiao/OpenAIGymSolution/tree/master/Acrobot-v1): a fixed policy written by Zhiqing Xiao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wound-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "\n",
    "import alogos as al\n",
    "import gym\n",
    "import unified_map as um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ccc0a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c2b71f",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "### 1) Environment\n",
    "\n",
    "Acrobot-v1: The aim is to swing the lower part of a two-link robot up to a given height, much like a gymnast. The agent observes current positions and velocities of the joints. It can act by applying positive torque (value 0), no torque (value 1), or negative torque (value 2) only to the joint between the two links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "loaded-conditions",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Acrobot-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cab54a",
   "metadata": {},
   "source": [
    "### 2) Functions to run single or multiple simulations\n",
    "\n",
    "It allows an agent to act in an environment and collect rewards until the environment signals it is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "saved-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_single_run(env, agent, render=False):\n",
    "    observation = env.reset()\n",
    "    episode_reward = 0.0\n",
    "    while True:\n",
    "        action = agent.decide(observation)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        episode_reward += reward\n",
    "        if render:\n",
    "            time.sleep(0.03)\n",
    "            env.render()\n",
    "        if done:\n",
    "            break\n",
    "    env.close()\n",
    "    return episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "subtle-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_multiple_runs(env, agent, n):\n",
    "    total_reward = sum(simulate_single_run(env, agent) for _ in range(n))\n",
    "    mean_reward = total_reward / n\n",
    "    return mean_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758bb84c",
   "metadata": {},
   "source": [
    "## Example solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3455163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sim = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862da83d",
   "metadata": {},
   "source": [
    "### 1) By Zhiqing Xiao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "changed-caribbean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-87.935"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Agent:\n",
    "    def decide(self, observation):\n",
    "        x0, y0, x1, y1, v0, v1 = observation\n",
    "        if v1 < -0.3:\n",
    "            action = 0\n",
    "        elif v1 > 0.3:\n",
    "            action = 2\n",
    "        else:\n",
    "            y = y1 + x0 * y1 + x1 * y0\n",
    "            if y > 0.:\n",
    "                action = 0\n",
    "            else:\n",
    "                action = 2\n",
    "        return action\n",
    "\n",
    "agent = Agent()\n",
    "simulate_multiple_runs(env, agent, num_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-death",
   "metadata": {},
   "source": [
    "### 2) By previous runs of evolutionary optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "gothic-chancellor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-84.36"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Agent:\n",
    "    def decide(self, observation):\n",
    "        x0, y0, x1, y1, v0, v1 = observation\n",
    "        output = (6.72*((v1*((5.01-0.80)**(5.94*(0.91*(v1+1.32)))))*((y0/v1)+5.87)))\n",
    "        action = 0 if output < 1.0 else 2\n",
    "        return action\n",
    "\n",
    "agent = Agent()\n",
    "simulate_multiple_runs(env, agent, num_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "large-fashion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-84.44"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Agent:\n",
    "    def decide(self, observation):\n",
    "        x0, y0, x1, y1, v0, v1 = observation\n",
    "        output = ((((7.79*((v0**3.36)**1.25))*x0)/((x1+2.54)-8.97))+((((((((v0+v0)/7.58)*(((8.04**v0)+8.23)+y0))-(x1-((v0+v0)/v1)))+x1)-y1)/(7.57/(5.20+y0)))-(((1.07+(4.97**6.10))-((x1+9.28)-8.64))**(2.01*((x0-((4.57/3.52)-4.46))-(0.54**y0))))))\n",
    "        action = 0 if output < 1.0 else 2\n",
    "        return action\n",
    "\n",
    "agent = Agent()\n",
    "simulate_multiple_runs(env, agent, num_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "legislative-conviction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-87.735"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Agent:\n",
    "    def decide(self, observation):\n",
    "        x0, y0, x1, y1, v0, v1 = observation\n",
    "        output = ((((((y0-y0)*4.98)*(v0-3.67))/y0)+(((v1-v1)*(((6.21/3.46)+7.92)*2.15))+(((v1/(3.44*x1))*((v0/v1)+1.08))*((v1+(3.69/(8.43+y1)))/((y1-((9.55*1.51)-((1.95**((7.15/x0)+v1))+((x0**8.25)-(((y1/8.41)-4.74)*9.79)))))*(((0.35*x1)/x0)/(((y1*(x1*x0))+(v0**1.24))**(((v0/v1)+1.08)*(((7.76**v1)/8.67)+(2.92/(9.24-3.81)))))))))))*(((5.77-y1)-(y1-(((7.05/((1.49/0.38)/(4.79**v0)))*y0)/v1)))/(v0*((v0**(y0*(7.96+x1)))+((v1+x0)/1.05)))))\n",
    "        action = 0 if output < 1.0 else 2\n",
    "        return action\n",
    "\n",
    "agent = Agent()\n",
    "simulate_multiple_runs(env, agent, num_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89204b9",
   "metadata": {},
   "source": [
    "## Definition of search space and goal\n",
    "\n",
    "### 1) Grammar\n",
    "\n",
    "This grammar defines a language of certain Python programs. Each program in that language can create an Agent who uses an algebraic expression of the observed variables to decide how to act in each situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc639ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebnf_text = \"\"\"\n",
    "PROGRAM = L0 NL L1 NL L2 NL L3 NL L4 NL L5\n",
    "\n",
    "L0 = \"class Agent:\"\n",
    "L1 = \"    def decide(self, observation):\"\n",
    "L2 = \"        x0, y0, x1, y1, v0, v1 = observation\"\n",
    "L3 = \"        output = \" EXPR\n",
    "L4 = \"        action = 0 if output < 1.0 else 2\"\n",
    "L5 = \"        return action\"\n",
    "\n",
    "NL = \"\\n\"\n",
    "\n",
    "EXPR = VAR | CONST | \"(\" EXPR OP EXPR \")\"\n",
    "VAR = \"x0\" | \"y0\" | \"x1\" | \"y1\" | \"v0\" | \"v1\"\n",
    "CONST = DIGIT \".\" DIGIT DIGIT\n",
    "OP = \"+\" | \"-\" | \"*\" | \"/\" | \"**\"\n",
    "DIGIT = \"0\" | \"1\" | \"2\" | \"3\" | \"4\" | \"5\" | \"6\" | \"7\" | \"8\" | \"9\"\n",
    "\"\"\"\n",
    "\n",
    "grammar = al.Grammar(ebnf_text=ebnf_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea79e669",
   "metadata": {},
   "source": [
    "### 2) Objective function\n",
    "\n",
    "The objective function gets a candidate solution (=a string of the grammar's language) and returns a fitness value for it. This is done by 1) executing the string as a Python program, so that it creates an agent object, and then 2) using the agent in multiple simulations to see how good it can handle different situations: the higher the total reward, the better is the candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bf81006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_agent(string):\n",
    "    local_vars = dict()\n",
    "    exec(string, None, local_vars)\n",
    "    Agent = local_vars['Agent']\n",
    "    return Agent()\n",
    "\n",
    "\n",
    "def objective_function(string):\n",
    "    agent = string_to_agent(string)\n",
    "    avg_reward = simulate_multiple_runs(env, agent, 10)\n",
    "    return avg_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0051fea",
   "metadata": {},
   "source": [
    "## Generate a random solution\n",
    "\n",
    "Check if grammar and objective function work as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "shared-empire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Agent:\n",
      "    def decide(self, observation):\n",
      "        x0, y0, x1, y1, v0, v1 = observation\n",
      "        output = ((4.29-5.84)/v0)\n",
      "        action = 0 if output < 1.0 else 2\n",
      "        return action\n"
     ]
    }
   ],
   "source": [
    "random_string = grammar.generate_string()\n",
    "print(random_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71e24a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-425.6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective_function(random_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bddd0a7",
   "metadata": {},
   "source": [
    "## Search for an optimal program\n",
    "\n",
    "Evolutionary optimization with random variation and non-random selection is used to find increasingly better candidate solutions.\n",
    "\n",
    "### 1) Parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "inside-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "ea = al.EvolutionaryAlgorithm(\n",
    "    grammar, objective_function, 'max',\n",
    "    max_or_min_fitness=-100, population_size=20, offspring_size=20,\n",
    "    evaluator=um.univariate.parallel.futures, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf65d3d",
   "metadata": {},
   "source": [
    "### 2) Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39e5f6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress         Generations      Evaluations      Runtime (sec)    Best fitness    \n",
      "..... ...\n",
      "\n",
      "Finished         8                159              31.2             -95.5           \n"
     ]
    }
   ],
   "source": [
    "best_ind = ea.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5c3cdf",
   "metadata": {},
   "source": [
    "### 3) Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddb018af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Agent:\n",
      "    def decide(self, observation):\n",
      "        x0, y0, x1, y1, v0, v1 = observation\n",
      "        output = ((0.50-((((1.57*x0)+x0)*(v0+5.75))*((((5.76-y0)**5.78)*v0)-((((0.33-x0)+5.41)*(3.24+5.91))*7.40))))-v0)\n",
      "        action = 0 if output < 1.0 else 2\n",
      "        return action\n"
     ]
    }
   ],
   "source": [
    "string = best_ind.phenotype\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "chinese-flower",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-100.05"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = string_to_agent(string)\n",
    "simulate_multiple_runs(env, agent, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fossil-deficit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-109.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate_single_run(env, agent, render=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
